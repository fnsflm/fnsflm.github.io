{"meta":{"title":"Hello World","subtitle":"","description":"","author":"FNSFLM","url":"http://fnsflm.xyz","root":"/"},"pages":[{"title":"hello world","text":"","path":"hello-world/index.html","date":"09-24","excerpt":""},{"title":"404","text":"","path":"404/index.html","date":"09-24","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"09-24","excerpt":""}],"posts":[{"title":"尝试配置hadoop环境","text":"尝试配置hadoop环境系统环境 操作系统：linux ubuntu 18.04 LTS java: openjdk 11.0.8 安装hadoop我的电脑上已经配置好了java环境，这里就不详细说了，官网上可以下载的java的jdk源码包，下载后配置环境变量即可，而ubuntu有自带的openjdk，可以用apt工具直接下载在apache hadoop官网上下载适合的版本，可以参考Hadoop2与Hadoop3的区别这里选择最新的3.1.4下载时间稍微有点长（可能是我网不好），下载后找个地方解压就好，很多教程里写的/usr/local/下，但个人因为权限的原因，不太喜欢存到这个目录下，自己找个地方存下了就是了，我存的地方是~/software配置环境变量vim ~/.bashrc修改.bashrc,$HADOOP_HOME就是解压后的文件夹的路径 1234export HADOOP_HOME=~/software/hadoop-3.1.4/export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport YARN_CONF_DIR=$HADOOP_HOME/etc/hadoopexport PATH=$PATH:$HADOOP_HOME/bin 再输入source ~/.bashrc更新配置，hadoop version查看是否安装成功 单机配置 参考：Ubuntu16.04下Hadoop的本地安装与配置 默认情况下，Hadoop被配置成以非分布式模式运行的一个独立Java进程。这对调试非常有帮助。 下面的例子将已解压的$HADOOP_HOME/etc/hadoop/*.xml 作为输入（其它文本文件也行），查找并显示匹配给定正则表达式的条目。输出写入到指定的output目录。为了不污染源码，随便找个文件夹执行以下操作（大部分教程实在hadoop解压的文件夹下执行） 123mkdir inputcp $HADOOP_HOME/etc/hadoop/*.xml ./input hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output &#x27;dfs[a-z.]+&#x27; 注： 目录下不能有output文件夹，否则会报错结果为：配置成功！ 伪分布配置ssh配置：如果ssh localhost能正常连接，如下图所示则可继续后续的步骤，其中可能出现报错：connect to host localhost port 22: Connection refused，此时使用apt重新下载ssh即可sudo apt-get install openssh-server，可以参考文章Ubuntu 安装配置SSH(ssh: connect to host localhost port 22: Connection refused问题的解决) 修改hadoop配置文件：配置文件在$HADOOPHOME/etc/hadoop文件夹下，要修改的是core-site.xml和hdfs-site.xml配置文件具体参数的说明可以参考：修改core-site.xml配置文件，修改hdfs-site.xml配置文件 core-site.xml: 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/tmp/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml: 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/tmp/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/tmp/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改之后执行hadoop namenode -format格式化一个新的分布式文件系统，$HADOOP_HOME/sbin/start-dfs.sh来开启namenode和datanode执行时会发生报错：这个是ssh秘钥出现了问题，参考普通用户ssh免密登陆完美解决(Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password))这篇文章，在~/.ssh目录下执行cat ./id_rsa.pub &gt;&gt; ./authorized_keys再次执行$HADOOP_HOME/sbin/start-dfs.sh，仍然发生报错：此时需要修改配置文件hadoop-env.sh，最后一行添加（如果已经export JAVA_HOME则需要修改）： 1export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ JAVA_HOME即为环境变量中的JAVA_HOME，如果已经配置但忘记在哪儿了可以在终端执行echo $JAVA_HOME获取再次执行$HADOOP_HOME/sbin/start-dfs.sh返回结果：再输入jsp列出了namenode和datanode说明配置成功","path":"2020/09/24/尝试配置hadoop环境/","date":"09-24","excerpt":"","tags":[]},{"title":"尝试使用navicat","text":"尝试使用navicatNavicat 是一套快速、可靠并价格相宜的数据库管理工具，专为简化数据库的管理及降低系统管理成本而设。它的设计符合数据库管理员、开发人员及中小企业的需要。Navicat 是以直觉化的图形用户界面而建的，让你可以以安全并且简单的方式创建、组织、访问并共用信息。 环境 linux ubuntu 18.04LTS mysql-5.7.31 navicat premium 学生认证 windows破解版可参考：Navicat介绍及安装 navicat的学生认证挺快的，只要你有学生邮箱，几乎立刻能注册学生认证链接没过多久就能在学生邮箱收到navicat的邮件，里面提供了激活码和下载地址：里面提供了三种版本，其中有一个没有提供，但在官网上可以下载，关于版本的介绍可以看看navicat的简单介绍这篇文章，这里先只使用navicat premium，以后用过其它版本后再更新该博客 使用navicat premium 启动下载的是一个AppImage的可执行文件，双击即可运行可能会弹出这样奇怪的界面：此时，给文件一个可执行的权限即可解决勾选允许作为程序可执行文件，或者在终端中用chmod更改权限也行激活过程就不赘述了，启动成功：2. 连接数据库点击测试连接，出现权限不够的问题：解决方法其实很简单，把主机里的localhost改成127.0.0.1就可以解决，如果还无法解决，可以修改/etc/mysql/mysql.conf.d/mysqld.cnf中的配置，可以参考文章：2002 - Can’t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock’ (13 “权限不够”)然后就能正常使用了：连接服务器上的mysql 用mysql直接连接–大失败 查阅资料： 配置防火墙，开启80端口、3306端口 &amp; iptables 使用详解 连接远程mysql数据库失败常见原因及解决办法 没有找到办法，服务器mysql的权限全给了，mysql.user 的root-host也是允许所有的访问(%)，防火墙也允许了3306端口的连接，各种尝试无果，以待后续解决 使用ssh连接这么简单的办法我居然没有找到，整个晚上时间都浪费了，悲点击最上面一行的ssh，使用ssh连接服务器再设置数据库在服务器上的使用，这里的host就是本机了连接成功： over!可喜可贺","path":"2020/09/24/尝试使用navicat/","date":"09-24","excerpt":"","tags":[]},{"title":"mysql数据库收集和导入数据集","text":"mysql数据库收集和导入数据集&nbsp; 环境linux ubuntu 18.04LTSmysql-5.7.31&nbsp; 数据集的收集 原贴【资源】史上最全数据集汇总 首先试了一下World Bank&nbsp;&nbsp;&nbsp;下载该数据集时出现submit始终无法点的情况，以待解决&nbsp;&nbsp;&nbsp; 再尝试RBI数据集&nbsp;首页就能看到许多数据集，可以用chrome翻译成中文随便点一个：&nbsp;点击pdf的图标，再点击pdf里的超链接，可以直接下载到数据集随便下一个，数据集如图所示：再将该表转为csv格式，方便后续数据库读取ELECT07022016_FEB18.csv&nbsp;数据集导入mysql数据库 mysql小数类型的使用 原贴：SQL Server 小数类型（float 和 decimal） 在数据库中创建表 12345678910111213create table ELECT07022016_FEB18(data varchar(200), rtgs_vo decimal(10,2),rtgs_va decimal(10,2), neft_vo decimal(10,2),neft_va decimal(10,2), cts_vo decimal(10,2),cts_va decimal(10,2),imps_vo decimal(10,2),imps_va decimal(10,2), nach_vo decimal(10,2),nach_va decimal(10,2), upi_vo decimal(10,2),upi_va decimal(10,2), ussd_vo decimal(10,2),ussd_va decimal(10,2), dccp_vo decimal(10,2),dccp_va decimal(10,2),ppi_vo decimal(10,2),ppi_va decimal(10,2),mb_vo decimal(10,2),mb_va decimal(10,2),total_vo decimal(10,2),total_va decimal(10,2)); 查了下load data infile的用法，暂时没找到忽略最后几行的办法，因此使用了较大的varchar来存储第一格下图是看最长的一个有多少字符 看看创建的表创建成功，然后感觉名字太复杂了，不好操作，改一下名： 1rename table ELECT07022016_FEB18 to eps_rd; 3. 用load导入到数据库中 参考：mysql中的load data infile用法 1234load data infile &#x27;/home/hjy/桌面/everyday-learning2/2020-9-15/ELECT07022016_FEB18.csv&#x27; into table mysql_learning.eps_rd character set gb2312 fields terminated by &#x27;,&#x27;; 出现报错： 参考：将csv 文件存入mysql 报错The MySQL server is running with the –secure-file-priv option so it cannot execute，显示secure_file_priv文件路径 1show variables like &#x27;%secure%&#x27;; 然后将文件拷贝至该路径下（文章中可以永久修改，解决该问题，但要重启mysql，为了简单起见，直接复制） 1sudo cp /home/hjy/桌面/everyday-learning2/2020-9-15/ELECT07022016_FEB18.csv /var/lib/mysql-files/ 再次导入，发生如下报错：参考：mysql 用load data 导入数据时，数据被截断问题 1set sql_mode=&#x27;&#x27;; 再次运行，导入成功：4. 后续操作 删除为空的行 1delete from eps_rd where data=&#x27;&#x27;; 拆分表 12create table month_eps as (select * from eps_rd where data like &#x27;___-%&#x27;);delete from month_eps where data=&#x27;Feb-18&#x27;; 把18年每天的数据分出来还有点麻烦，这里用了正则表达式 参考：MySQL正则表达式 1234create table feb_esp as select * from eps_rd where data regexp &#x27;^[0-9]&#x27; and data not like &#x27;_.%&#x27;; 再将其它信息存起来 1create table note as select data from eps_rd where data like &#x27;____%&#x27; and data not like &#x27;___-__&#x27;; 最后，我想给更改一下列名，把data改成notes可在网上没查到方法（好多写的是用sp_name更改，但我不会用），说来惭愧。我的java IDE：IntelliJ IDEA里有连结数据库的功能，然后用里面的工具成功更改列名。 1alter table note change data notes varchar(200) null; over！","path":"2020/09/24/mysql数据库收集和导入数据集/","date":"09-24","excerpt":"","tags":[]},{"title":"Linux下vscode C语言 对pow、exp未定义引用问题","text":"Linux下vscode C语言 对pow、exp未定义引用问题@[TOC](Linux下vscode C语言 对pow、exp未定义引用) 问题描述头文件使用math库时会出现“未定义引用”问题报错： /tmp/cct7CPFw.o：在函数‘main’中：19012705.c:(.text+0x88)：对‘pow’未定义的引用collect2: error: ld returned 1 exit status 源代码： 1234567891011121314#include &lt;stdio.h&gt;#include &lt;math.h&gt;#define e 2.718281828int main()&#123; float temperature, dewpoint, humidex; while (scanf(&quot;T %f D %f&quot;, &amp;temperature, &amp;dewpoint) == 2) &#123; getchar(); humidex = temperature + (0.5555) * (-10 + 6.11 * pow(e, (5417.7530 * ((1 / 273.16) - (1 / (dewpoint + 273.16)))))); printf(&quot;T %.1f D %.1f H %.1f\\n&quot;, temperature, dewpoint, humidex); &#125; return 0;&#125; 在linux终端下也会出现一样问题 原因linux中gcc没有默认链接math库 解决方法vscode工作区文件夹下有一个.vscode文件夹（没有就创建），在该文件下打开settings.json（没有就创建）左侧的4复制到右侧在“C”如图加上-lm，保存即可 结果` 补充linux上c语言的函数库在/usr/lib/目录下，以lib*开头.so为后缀,*为库的名称，比如math库是libm.so,stdio库是libc.so。gcc命令末尾-l库名称就能链接函数库 ………………………………………………………………………………………………………….. 补充以上内容其实是对code runner插件问题的解决，在调试中仍然会出现问题，这时需要对./.vscode/tasks.json文件进行修改","path":"2020/09/24/Linux下vscode C语言 对pow、exp未定义引用问题/","date":"09-24","excerpt":"","tags":[]},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","path":"2020/09/24/hello-world/","date":"09-24","excerpt":"","tags":[]}],"categories":[],"tags":[]}